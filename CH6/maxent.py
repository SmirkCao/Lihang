# -*-coding:utf-8-*-
# Project:  Lihang
# Filename: maxent
# Date: 8/24/18
# Author: ğŸ˜ <smirk dot cao at gmail dot com>
import argparse
import logging
from collections import defaultdict
import math
import time
import pandas as pd
import numpy as np
from sklearn.cross_validation import train_test_split
from sklearn.metrics import accuracy_score


class Maxent(object):
    def __init__(self):
        # N è®­ç»ƒé›†æ ·æœ¬å®¹é‡
        pass

    def init_params(self, x, x):
        self.X_ = x
        self.Y_ = set()

        self._Pxy_Px(x, y)

        self.N = len(x)  # è®­ç»ƒé›†å¤§å°
        self.n = len(self.Pxy)  # ä¹¦ä¸­(x,y)å¯¹æ•°
        self.M = 10000.0  # ä¹¦91é¡µé‚£ä¸ªMï¼Œä½†å®é™…æ“ä½œä¸­å¹¶æ²¡æœ‰ç”¨é‚£ä¸ªå€¼
        # å¯è®¤ä¸ºæ˜¯å­¦ä¹ é€Ÿç‡

        self.build_dict()
        self._EPxy()

    def build_dict(self):
        # å…¶å®è¿™ä¸ªçš„åšæ³•, æ˜¯TFIDFå˜›
        self.id2xy = dict()
        self.xy2id = dict()

        for idx, (x, y) in enumerate(self.Pxy):
            self.id2xy[idx] = (x, y)
            self.xy2id[(x, y)] = idx

    def _px_pxy(self, x, y):
        self.Pxy = defaultdict(int)
        self.Px = defaultdict(int)

        # ç›¸å½“äºæŒ‰ç…§ç‰¹å¾ç»Ÿè®¡äº†
        for idx in range(len(x)):
            x_, y_ = x[idx], y[idx]
            self.Y_.add(y_)

            for x__ in x_:
                self.Pxy[(x__, y)] += 1
                self.Px[x__] += 1

    def _EPxy(self):
        '''
        è®¡ç®—ä¹¦ä¸­82é¡µæœ€ä¸‹é¢é‚£ä¸ªæœŸæœ›
        '''
        self.EPxy = defaultdict(float)
        for id in range(self.n):
            (x, y) = self.id2xy[id]
            self.EPxy[id] = float(self.Pxy[(x, y)]) / float(self.N)

    def _pyx(self, x, y):
        result = 0.0
        for x_ in x:
            if self.fxy(x_, y):
                id = self.xy2id[(x_, y)]
                result += self.w[id]
        return math.exp(result), y

    def _probality(self, x):
        '''
        è®¡ç®—ä¹¦85é¡µå…¬å¼6.22å’Œ6.23, è¿™ä¸ªè¡¨ç¤ºçš„æ˜¯æœ€å¤§ç†µæ¨¡å‹.
        '''
        Pyxs = [(self._pyx(x, y)) for y in self.Y_]
        Z = sum([prob for prob, y in Pyxs])
        return [(prob / Z, y) for prob, y in Pyxs]

    def _EPx(self):
        '''
        è®¡ç®—ä¹¦83é¡µæœ€ä¸Šé¢é‚£ä¸ªæœŸæœ›
        '''
        self.EPx = [0.0 for i in range(self.n)]

        for i, X in enumerate(self.X_):
            Pyxs = self._probality(X)

            for x in X:
                for Pyx, y in Pyxs:
                    if self.fxy(x, y):
                        id = self.xy2id[(x, y)]

                        self.EPx[id] += Pyx * (1.0 / self.N)

    def fxy(self, x, y):
        return (x, y) in self.xy2id

    def fit(self, x, y):
        self.init_params(x, y)
        # IIS ç®—æ³•æµç¨‹ é¢, ä¹Ÿå¯èƒ½æ˜¯GIS, çœ‹ä¸‹å†
        # åˆå§‹åŒ–æƒé‡å‘å…¨ä¸º0
        # self.w = [0.0 for i in range(self.n)]
        self.w = np.zeros(self.n)
        # æ•´ä¸ªè¿™ä¸ªè¿‡ç¨‹éƒ½å¯ä»¥ç²¾ç®€
        max_iteration = 1000
        for times in range(max_iteration):
            logger.info('iterater times %d' % times)
            sigmas = []
            self._EPx()
            # æ‹¿åˆ°sigmaå‘é‡
            for i in range(self.n):
                sigma = 1 / self.M * math.log(self.EPxy[i] / self.EPx[i])
                sigmas.append(sigma)
            # å¥½å§, è¿™ä»½ä»£ç ä¹Ÿæ˜¯æ”¹çš„. åº”è¯¥ç®—æ³•ç”¨çš„å°±æ˜¯GISäº†ï¼Œ ç½‘ä¸Šæµä¼ æœ€å¹¿çš„åº”è¯¥å°±æ˜¯è¿™ä¸ªGISçš„ä¾‹å­äº†ã€‚
            # æ–‡ç« ä¸­å‚è€ƒäº†è¿™ä¸ªæ–‡çŒ®ã€Šè¯­è¨€ä¿¡æ¯å¤„ç†æŠ€æœ¯ä¸­çš„æœ€å¤§ç†µæ¨¡å‹æ–¹æ³•ã€‹ä»¥åŠå¦å¤–ä¸€ä¸ªåšå®¢æ–‡ç« 
            # http://www.cnblogs.com/hexinuaa/p/3353479.html
            # ç„¶è€Œï¼Œè¿™ä¸ªæ–‡ç« æ²¡æœ‰ä»‹ç»ç¿»è¯‘çš„æ˜¯ä»€ä¹ˆï¼Œ æºå¤´æ˜¯ã€ŠA Brief Maxent Toturialã€‹(Berger, 1995)
            # è¿™ä¸ªé‡Œé¢åº”è¯¥æ˜¯æœ€åŸå§‹çš„ä»£ç ã€‚https://vimsky.com/article/776.html
            # if len(filter(lambda x: abs(x) >= 0.01, sigmas)) == 0:
            #     break
            # æ›´æ–°å‚æ•°w
            self.w = [self.w[i] + sigmas[i] for i in range(self.n)]

    def predict(self, x):
        results = []
        for test in x:
            result = self._probality(test)
            results.append(max(result, key=lambda x: x[0])[1])
        return results


def rebuild_features(features):
    '''
    å°†åŸfeatureçš„ï¼ˆa0,a1,a2,a3,a4,...ï¼‰
    å˜æˆ (0_a0,1_a1,2_a2,3_a3,4_a4,...)å½¢å¼
    '''
    new_features = []
    for feature in features:
        new_feature = []
        for i, f in enumerate(feature):
            new_feature.append(str(i) + '_' + str(f))
        new_features.append(new_feature)
    return new_features


if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    logger = logging.getLogger(__name__)

    ap = argparse.ArgumentParser()
    ap.add_argument("-i", "--image", required=True,
                    help="path to input image")
    args = vars(ap.parse_args())

    logger.info('Start read data')
    time_1 = time.time()
    raw_data = pd.read_csv('../data/train_binary.csv', header=0)
    data = raw_data.values
    imgs = data[0::, 1::]
    labels = data[::, 0]

    # é€‰å– 2/3 æ•°æ®ä½œä¸ºè®­ç»ƒé›†ï¼Œ 1/3 æ•°æ®ä½œä¸ºæµ‹è¯•é›†
    train_features, test_features, train_labels, test_labels = train_test_split(imgs, labels,
                                                                                test_size=0.33, random_state=23323)
    # ç‰¹å¾å·¥ç¨‹
    train_features = rebuild_features(train_features)
    test_features = rebuild_features(test_features)

    time_2 = time.time()
    logger.info('read data cost %d second' % (time_2 - time_1))
    logger.info('Start training')
    met = Maxent()
    met.fit(train_features, train_labels)

    time_3 = time.time()
    logger.info('training cost %d second' % (time_3 - time_2))
    logger.info('Start predicting')
    test_predict = met.predict(test_features)
    time_4 = time.time()
    logger.info('predicting cost %d second' % (time_4 - time_3))
    score = accuracy_score(test_labels, test_predict)
    logger.info("The accruacy socre is %d" % score)
