#! /usr/bin/env python
# ! -*- coding=utf-8 -*-
# Project:  Lihang
# Filename: bmm
# Date: 10/24/18
# Author: ğŸ˜ <smirk dot cao at gmail dot com>
import numpy as np
import argparse
import logging


class BMM(object):
    def __init__(self,
                 n_components=2,
                 max_iter=100,
                 tol=1e-3,
                 mu=None,
                 alpha=None,
                 verbose=False):
        """

        :param n_components:
        :param max_iter:
        :param tol:
        :param mu: è¿™é‡Œå¯èƒ½è¦çœ‹ä¸€ä¸‹å’Œä¹¦ä¸­çš„p,qå¯¹åº”å…³ç³», p=0.6, q=0.7, å¯¹åº”äº†X=1 X=0çš„æƒ…å†µ, æ‰€ä»¥[0.7, 0.6]
        :param alpha:
        :param verbose:
        """
        # k
        self.n_components = n_components
        self.max_iter = max_iter
        self.tol = tol
        # N
        self.m = 0
        self.n = 0
        self.gamma = None
        self.n_iter_ = 0
        self.mu = mu
        self.alpha = alpha
        self.X = None
        self.label = None
        self.verbose = verbose

    def fit(self,
            X,
            y=None):
        k = self.n_components
        # self.m, self.n = X.shape
        self.m = X.shape[0]
        N = self.m
        # å¦‚æœn > 1 , åˆ†è§£æˆnä¸ªæ¨¡å‹è®­ç»ƒ, ç»“æœå†æ‹¼å›æ¥
        if y is not None:
            self.label = y
        # X: (N, 2)
        self.X = np.eye(k)[X]
        # gamma: (N, k), æ ·æœ¬å¯¹å­æ¨¡å‹çš„å“åº”åº¦gamma_jk, æŒ‰jæ±‚å’Œåº”è¯¥æ˜¯1
        if self.gamma is None:
            self.gamma = np.full((N, k), 1/k)

        # alpha: (k) , å­æ¨¡å‹å¯¹æ··åˆæ¨¡å‹çš„è´¡çŒ®, æ±‚å’Œä¸º1
        if self.alpha is None:
            self.alpha = 0.5
        self.alpha = np.stack((1 - self.alpha, self.alpha), axis=-1)

        # mu: (k, 2) 2æ˜¯ä¸ºäº†åšçŸ©é˜µä¹˜æ³•, ç›¸å¯¹for loopæ•ˆç‡åº”è¯¥ä¼šé«˜, è¿™é‡Œtodo: benchmark
        if self.mu is None:
            self.mu = np.full(k, 1/k)

        self.mu = np.stack((1 - self.mu, self.mu), axis=-1)

        for i in range(self.max_iter):
            # print(self.alpha, "\n", self.mu[:, 0], "\n", self.gamma, "\n")
            self.do_e_step()
            self.do_m_step()
            if self.verbose:
                logger.info("alpha %s" % self.alpha)
                logger.info(self.mu)
            if self.is_convergence():
                break

    def is_convergence(self):

        return False

    def density(self):
        # Bernoulli Distribution Density
        rst = np.dot(self.X, self.mu.T)
        return rst

    def do_e_step(self):
        # æ›´æ–°gamma
        self.gamma = self.density() * self.alpha
        z = np.sum(self.gamma, axis=1).reshape(-1, 1)
        self.gamma /= z
        return self

    def do_m_step(self):
        nk = np.sum(self.gamma, axis=0)
        # update mu, æ³¨æ„è¿™é‡ŒX[:, 1] ä¸­çš„1 æ¥è‡ªXçš„å–å€¼ä¸º1çš„æ„æ€.
        # p,q å¯¹åº”çš„æ˜¯A=1, B=1, A=0, C=1, æ³¨æ„è¿™é‡Œç”¨æ ·æœ¬åˆ·
        self.mu = np.sum(self.gamma * self.X[:, 1].reshape(-1, 1), axis=0) / nk
        self.mu = np.stack((1 - self.mu, self.mu), axis=-1)

        # update alpha
        self.alpha = nk / self.m
        return self

    def predict(self, X):
        pass

    def sample(self,
               n_samples=1):
        pass


if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    logger = logging.getLogger(__name__)

    ap = argparse.ArgumentParser()
    ap.add_argument("-p", "--path", required=False, help="path to input data file")
    args = vars(ap.parse_args())

else:
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    logger = logging.getLogger(__name__)

    ap = argparse.ArgumentParser()
    ap.add_argument("-p", "--path", required=False, help="path to input data")
    args = vars(ap.parse_args())
